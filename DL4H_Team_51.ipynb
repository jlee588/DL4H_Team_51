{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team github link: https://github.com/jlee588/DL4H_Team_51"
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bring in necessary files from github\n"
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jlee588/DL4H_Team_51"
      ],
      "metadata": {
        "id": "Cduo2t8Oh_Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "This is an introduction to your report, you should edit this text/markdown section to compose. In this text/markdown, you should introduce:\n",
        "\n",
        "*   Background of the problem\n",
        "  * This paper aims to solve the problem of predicting drug to drug interaction events for pharmaceutical research.\n",
        "  * The importance of solving this problem is that most research has been done on whether two drugs interact with each other but not many have analyzed the consequential effects of when two drugs interact with each other. The paper also stated that \"67% of elderly Americans took five or more medications in 2010-2011.\" This is important because with so many people taking multiple medications, it is imperative that we ensure those medications, if taken together, will still be safe to take.\n",
        "  * This problem can be difficult because the most relevant and diverse features must be chosen to use in a deep neural network in order to retrieve the most informative results from the model.It is important to choose the right amount of diverse features that will all individually contribute to the final results because that is how we will get the most informative model.\n",
        "  * The current state of the art methods in DDI predictions include DeepDDI, random forest, logistic regression, and K-nearest neighbor. From the paper, we will see that these methods have accuracy results of 0.8371,0.7775,0.7214, and 0.7920 respectively. They also have an area under the precision-recall curve of 0.8899,0.8349,0.7716, and 0.8400 respectively.\n",
        "\n",
        "*   Paper explanation\n",
        "  * The paper proposes a DNN-based architecture that combines a variety of drug features with deep learning to predict the DDI events. The features used in this model will be chemical substructures, targets, enzymes and pathways.\n",
        "  * The innovations of this method include using semantic analysis on the descriptions of known DDIs from the DrugBank dataset to construct an interaction event dataset and then using diverse features from drugs to predict DDI events.\n",
        "  * According to the paper, the results of the DDIMDL model outperformed all 4 other state of the art algorithms with an accuracy of 0.8852 and an area under the precision-recall curve of 0.9208.\n",
        "  * The contributions to the research regime from this paper include a multimodal deep learning framework that outperforms other state of the art methods in regards to DDI event predictions. This can be very helpful for the pharmaceutical industry as there is now an even higher chance of drug to drug interactions being detected and the adverse effects of these drugs being taken together can be avoided."
      ],
      "metadata": {
        "id": "MQ0sNuMePBXx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "\n",
        "\n",
        "1.   Hypothesis 1: A DNN-based architecture, specifically named DDIMDL, is superior to other state of the art algorithms in regards to predicting DDIs. To test this, our model will compare models that use the DDIMDL algorithm to predict DDIs with other state of the art algorithms such as random forest, logistic regression, gradient boosting decision tree, and K-nearest neighbor while all other aspects remain the same.\n",
        "Our ablations planned are to remove one or two layers from the model and compare those results from the original model.\n",
        "\n",
        "To reproduce the paper's results, we plan to modernize the code to work around deprecated functions and this will be shown in the commented out code throughout the file that will be replaced with the modern code below it.\n",
        "\n"
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import  packages you need\n",
        "import numpy as np\n",
        "# from google.colab import drive\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "#from tensorflow import set_random_seed\n",
        "#set_random_seed(2)\n",
        "import csv\n",
        "import sqlite3\n",
        "import time\n",
        "import numpy as np\n",
        "# import stanfordnlp\n",
        "# stanfordnlp.download('en')\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression  # Corrected import\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "Data includes raw data (drug, event, interaction) tables from event.db, pre-procssed data (extraction) table from event.db, descriptive statistics (size of each table and basic info), and data processing (feature engineering).\n",
        "  * Source of the data: pre-processed data using Drugbank (https://go.drugbank.com/) is available from the public github of the paper (https://github.com/YifanDengWHU/DDIMDL) as a database file (event.db). A separate NLP script (NLPProcess.py available in github) was used to extract drug interactions to form extractions table in event.db\n",
        "  * Statistics: Functions to print out basic descriptive statistics are defined below.\n",
        "  * Data process: Data processing functions to split the data and convert them to feature vectors are defined below.\n",
        "  * Illustration: Functions for printing results of the model are defined below."
      ],
      "metadata": {
        "id": "2NbPHUTMbkD3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "All raw data needed are in event.db file\n",
        "event.db is also available in public github: https://github.com/jlee588/DL4H_Team_51\n",
        "Each dataframe is constructed by connecting to the event.db file via a sql query as shown below\n",
        "'''\n",
        "\n",
        "raw_data_dir = '/content/DL4H_Team_51/event.db'\n",
        "\n",
        "def load_raw_data(raw_data_dir):\n",
        "  # implement this function to load raw data to dataframe/numpy array/tensor\n",
        "  conn = sqlite3.connect(raw_data_dir)\n",
        "  df_drug = pd.read_sql('select * from drug;', conn)\n",
        "  df_event = pd.read_sql('select * from event_number;', conn)\n",
        "  df_interaction = pd.read_sql('select * from event;', conn)\n",
        "  return df_drug, df_event, df_interaction\n",
        "\n",
        "df_drug, df_event, df_interaction  = load_raw_data(raw_data_dir)\n",
        "conn = sqlite3.connect(raw_data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate statistics\n",
        "'''\n",
        "1.drug contains 572 kinds of drugs and their features.\n",
        "2.event contains the 37264 DDIs between the 572 kinds of drugs.\n",
        "3.event_number lists the kinds of DDI events and their occurence frequency.\n",
        "'''\n",
        "def calculate_stats(dataframes):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "  for df_name, df in dataframes.items():\n",
        "        print(f\"Statistics for {df_name}:\")\n",
        "        print(\"Shape:\", df.shape)\n",
        "        print(\"Info:\")\n",
        "        df.info()\n",
        "        print(\"=\"*40)\n",
        "\n",
        "calculate_stats({\n",
        "    'Drug': df_drug,\n",
        "    'Event Number': df_event,\n",
        "    'Interaction': df_interaction\n",
        "})"
      ],
      "metadata": {
        "id": "HwfhHOxkB4UU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This function works with raw data (df_drug) table and feature_vector function\n",
        "to create a feature vector with new labels\n",
        "It creates and returns:\n",
        "new_feature: array with combined feature vectors for drug pairs\n",
        "new_label: array of labels for each drug pair interaction\n",
        "event_num: number of events to be used with other functions\n",
        "\n",
        "'''\n",
        "def prepare(df_drug, feature_list, vector_size,mechanism,action,drugA,drugB):\n",
        "    d_label = {}\n",
        "    d_feature = {}\n",
        "    # Transfrom the interaction event to number\n",
        "    # Splice the features\n",
        "    d_event=[]\n",
        "    for i in range(len(mechanism)):\n",
        "        d_event.append(mechanism[i]+\" \"+action[i])\n",
        "    label_value = 0\n",
        "    count={}\n",
        "    for i in d_event:\n",
        "        if i in count:\n",
        "            count[i]+=1\n",
        "        else:\n",
        "            count[i]=1\n",
        "    list1 = sorted(count.items(), key=lambda x: x[1],reverse=True)\n",
        "    for i in range(len(list1)):\n",
        "        d_label[list1[i][0]]=i\n",
        "    vector = np.zeros((len(np.array(df_drug['name']).tolist()), 0), dtype=float)\n",
        "    for i in feature_list:\n",
        "        vector = np.hstack((vector, feature_vector(i, df_drug, vector_size)))\n",
        "    # Transfrom the drug ID to feature vector\n",
        "    for i in range(len(np.array(df_drug['name']).tolist())):\n",
        "        d_feature[np.array(df_drug['name']).tolist()[i]] = vector[i]\n",
        "    # Use the dictionary to obtain feature vector and label\n",
        "    new_feature = []\n",
        "    new_label = []\n",
        "    name_to_id = {}\n",
        "    for i in range(len(d_event)):\n",
        "        new_feature.append(np.hstack((d_feature[drugA[i]], d_feature[drugB[i]])))\n",
        "        new_label.append(d_label[d_event[i]])\n",
        "    new_feature = np.array(new_feature)\n",
        "    new_label = np.array(new_label)\n",
        "    return (new_feature, new_label, event_num)"
      ],
      "metadata": {
        "id": "Rqc_55vsaE0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This function first defines a function to create a Jaccard similarity matrix to\n",
        "be used to quantify the similarity between every pair of drugs based on shared\n",
        "features.\n",
        "It then extracts and compiles a list of unique features from df_drug table\n",
        "Jaccard function is used to generate similarity matrices\n",
        "PCA is applied to reduce the dimensionality to vector_size\n",
        "'''\n",
        "def feature_vector(feature_name, df, vector_size):\n",
        "    # df are the 572 kinds of drugs\n",
        "    # Jaccard Similarity\n",
        "    # np.matrix outdated\n",
        "    # def Jaccard(matrix):\n",
        "    #     matrix = np.mat(matrix)\n",
        "    #     numerator = matrix * matrix.T\n",
        "    #     denominator = np.ones(np.shape(matrix)) * matrix.T + matrix * np.ones(np.shape(matrix.T)) - matrix * matrix.T\n",
        "    #     return numerator / denominator\n",
        "    def Jaccard(matrix):\n",
        "        matrix = np.array(matrix)\n",
        "        numerator = matrix.dot(matrix.T)\n",
        "        denominator = (np.ones(matrix.shape) @ matrix.T) + (matrix @ np.ones(matrix.T.shape)) - (matrix.dot(matrix.T))\n",
        "        denominator[denominator == 0] = 1\n",
        "        return numerator / denominator\n",
        "\n",
        "    all_feature = []\n",
        "    drug_list = np.array(df[feature_name]).tolist()\n",
        "    # Features for each drug, for example, when feature_name is target, drug_list=[\"P30556|P05412\",\"P28223|P46098|……\"]\n",
        "    for i in drug_list:\n",
        "        for each_feature in i.split('|'):\n",
        "            if each_feature not in all_feature:\n",
        "                all_feature.append(each_feature)  # obtain all the features\n",
        "    feature_matrix = np.zeros((len(drug_list), len(all_feature)), dtype=float)\n",
        "    df_feature = DataFrame(feature_matrix, columns=all_feature)  # Consrtuct feature matrices with key of dataframe\n",
        "    for i in range(len(drug_list)):\n",
        "        for each_feature in df[feature_name].iloc[i].split('|'):\n",
        "            df_feature[each_feature].iloc[i] = 1\n",
        "    sim_matrix = Jaccard(np.array(df_feature))\n",
        "\n",
        "    sim_matrix1 = np.array(sim_matrix)\n",
        "    count = 0\n",
        "    pca = PCA(n_components=vector_size)  # PCA dimension\n",
        "    pca.fit(sim_matrix)\n",
        "    sim_matrix = pca.transform(sim_matrix)\n",
        "    return sim_matrix"
      ],
      "metadata": {
        "id": "gIvGB8nWahwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This function is used to assign labels and split the dataset for KFold cross-\n",
        "validation.\n",
        "It assigns a fold number 'k_num' to each test index in the index_all_classes array\n",
        "'''\n",
        "def get_index(label_matrix, event_num, seed, CV):\n",
        "    index_all_class = np.zeros(len(label_matrix))\n",
        "    for j in range(event_num):\n",
        "        index = np.where(label_matrix == j)\n",
        "        kf = KFold(n_splits=CV, shuffle=True, random_state=seed)\n",
        "        k_num = 0\n",
        "        for train_index, test_index in kf.split(range(len(index[0]))):\n",
        "            index_all_class[index[0][test_index]] = k_num\n",
        "            k_num += 1\n",
        "\n",
        "    return index_all_class"
      ],
      "metadata": {
        "id": "1MQqnbm5FHyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ],
      "metadata": {
        "id": "3muyDPFPbozY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The main model (DDIMDL) is defined below.\n",
        "All the layers needed (Dense, Dropout, BatchNormalization, Activation) are defined with input_features and output_features\n",
        "Loss function is categorical_crossentropy\n",
        "Adam optimizer is used for the model\n",
        "'''\n",
        "\n",
        "def DNN():\n",
        "    train_input = Input(shape=(vector_size * 2,), name='Inputlayer')\n",
        "    train_in = Dense(512, activation='relu')(train_input)\n",
        "    train_in = BatchNormalization()(train_in)\n",
        "    train_in = Dropout(droprate)(train_in)\n",
        "    train_in = Dense(256, activation='relu')(train_in)\n",
        "    train_in = BatchNormalization()(train_in)\n",
        "    train_in = Dropout(droprate)(train_in)\n",
        "    train_in = Dense(event_num)(train_in)\n",
        "    out = Activation('softmax')(train_in)\n",
        "    model = Model(inputs=train_input, outputs=out)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "gQ2eyBBRibCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Functions are defined below to evaluate each classifier using various metrics\n",
        "Results are saved as arrays and returned as outputs\n",
        "We can calculate accuracy, roc_aupr, roc_auc, f1_score, precision, recall\n",
        "These metrics are organized by each classifier for easy comparison\n",
        "'''\n",
        "def evaluate(pred_type, pred_score, y_test, event_num, set_name):\n",
        "    all_eval_type = 11\n",
        "    result_all = np.zeros((all_eval_type, 1), dtype=float)\n",
        "    each_eval_type = 6\n",
        "    result_eve = np.zeros((event_num, each_eval_type), dtype=float)\n",
        "    # y_one_hot = label_binarize(y_test, np.arange(event_num))\n",
        "    # pred_one_hot = label_binarize(pred_type, np.arange(event_num))\n",
        "    y_one_hot = label_binarize(y_test, classes=np.arange(event_num))\n",
        "    pred_one_hot = label_binarize(pred_type, classes=np.arange(event_num))\n",
        "\n",
        "    precision, recall, th = multiclass_precision_recall_curve(y_one_hot, pred_score)\n",
        "\n",
        "    result_all[0] = accuracy_score(y_test, pred_type)\n",
        "    result_all[1] = roc_aupr_score(y_one_hot, pred_score, average='micro')\n",
        "    result_all[2] = roc_aupr_score(y_one_hot, pred_score, average='macro')\n",
        "    result_all[3] = roc_auc_score(y_one_hot, pred_score, average='micro')\n",
        "    result_all[4] = roc_auc_score(y_one_hot, pred_score, average='macro')\n",
        "    result_all[5] = f1_score(y_test, pred_type, average='micro')\n",
        "    result_all[6] = f1_score(y_test, pred_type, average='macro')\n",
        "    result_all[7] = precision_score(y_test, pred_type, average='micro', zero_division=0)\n",
        "    result_all[8] = precision_score(y_test, pred_type, average='macro', zero_division=0)\n",
        "    result_all[9] = recall_score(y_test, pred_type, average='micro')\n",
        "    result_all[10] = recall_score(y_test, pred_type, average='macro')\n",
        "    for i in range(event_num):\n",
        "        result_eve[i, 0] = accuracy_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel())\n",
        "        result_eve[i, 1] = roc_aupr_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
        "                                          average=None)\n",
        "        result_eve[i, 2] = roc_auc_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
        "                                         average=None)\n",
        "        result_eve[i, 3] = f1_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
        "                                    average='binary')\n",
        "        result_eve[i, 4] = precision_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
        "                                           average='binary', zero_division=0)\n",
        "        result_eve[i, 5] = recall_score(y_one_hot.take([i], axis=1).ravel(), pred_one_hot.take([i], axis=1).ravel(),\n",
        "                                        average='binary')\n",
        "    return [result_all, result_eve]\n",
        "\n",
        "\n",
        "def self_metric_calculate(y_true, pred_type):\n",
        "    y_true = y_true.ravel()\n",
        "    y_pred = pred_type.ravel()\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true.reshape((-1, 1))\n",
        "    if y_pred.ndim == 1:\n",
        "        y_pred = y_pred.reshape((-1, 1))\n",
        "    y_true_c = y_true.take([0], axis=1).ravel()\n",
        "    y_pred_c = y_pred.take([0], axis=1).ravel()\n",
        "    TP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    FP = 0\n",
        "    for i in range(len(y_true_c)):\n",
        "        if (y_true_c[i] == 1) and (y_pred_c[i] == 1):\n",
        "            TP += 1\n",
        "        if (y_true_c[i] == 1) and (y_pred_c[i] == 0):\n",
        "            FN += 1\n",
        "        if (y_true_c[i] == 0) and (y_pred_c[i] == 1):\n",
        "            FP += 1\n",
        "        if (y_true_c[i] == 0) and (y_pred_c[i] == 0):\n",
        "            TN += 1\n",
        "    print(\"TP=\", TP, \"FN=\", FN, \"FP=\", FP, \"TN=\", TN)\n",
        "    return (TP / (TP + FP), TP / (TP + FN))\n",
        "\n",
        "\n",
        "def multiclass_precision_recall_curve(y_true, y_score):\n",
        "    y_true = y_true.ravel()\n",
        "    y_score = y_score.ravel()\n",
        "    if y_true.ndim == 1:\n",
        "        y_true = y_true.reshape((-1, 1))\n",
        "    if y_score.ndim == 1:\n",
        "        y_score = y_score.reshape((-1, 1))\n",
        "    y_true_c = y_true.take([0], axis=1).ravel()\n",
        "    y_score_c = y_score.take([0], axis=1).ravel()\n",
        "    precision, recall, pr_thresholds = precision_recall_curve(y_true_c, y_score_c)\n",
        "    return (precision, recall, pr_thresholds)\n",
        "\n",
        "\n",
        "def roc_aupr_score(y_true, y_score, average=\"macro\"):\n",
        "    def _binary_roc_aupr_score(y_true, y_score):\n",
        "        precision, recall, pr_thresholds = precision_recall_curve(y_true, y_score)\n",
        "        return auc(recall, precision)\n",
        "\n",
        "    def _average_binary_score(binary_metric, y_true, y_score, average):  # y_true= y_one_hot\n",
        "        if average == \"binary\":\n",
        "            return binary_metric(y_true, y_score)\n",
        "        if average == \"micro\":\n",
        "            y_true = y_true.ravel()\n",
        "            y_score = y_score.ravel()\n",
        "        if y_true.ndim == 1:\n",
        "            y_true = y_true.reshape((-1, 1))\n",
        "        if y_score.ndim == 1:\n",
        "            y_score = y_score.reshape((-1, 1))\n",
        "        n_classes = y_score.shape[1]\n",
        "        score = np.zeros((n_classes,))\n",
        "        for c in range(n_classes):\n",
        "            y_true_c = y_true.take([c], axis=1).ravel()\n",
        "            y_score_c = y_score.take([c], axis=1).ravel()\n",
        "            score[c] = binary_metric(y_true_c, y_score_c)\n",
        "        return np.average(score)\n",
        "\n",
        "    return _average_binary_score(_binary_roc_aupr_score, y_true, y_score, average)"
      ],
      "metadata": {
        "id": "sw4yXxXsrLg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Training loop as well as cross validation is defined in below function\n",
        "Based on what type of classifier we're using, corresponding model will be used for training\n",
        "For DDIMDL, number of epochs and batch_size can be specified\n",
        "'''\n",
        "number_epochs = 1\n",
        "def cross_validation(feature_matrix, label_matrix, clf_type, event_num, seed, CV, set_name):\n",
        "    all_eval_type = 11\n",
        "    result_all = np.zeros((all_eval_type, 1), dtype=float)\n",
        "    each_eval_type = 6\n",
        "    result_eve = np.zeros((event_num, each_eval_type), dtype=float)\n",
        "    y_true = np.array([])\n",
        "    y_pred = np.array([])\n",
        "    y_score = np.zeros((0, event_num), dtype=float)\n",
        "    index_all_class = get_index(label_matrix, event_num, seed, CV)\n",
        "    matrix = []\n",
        "    if type(feature_matrix) != list:\n",
        "        matrix.append(feature_matrix)\n",
        "        # =============================================================================\n",
        "        #     elif len(np.shape(feature_matrix))==3:\n",
        "        #         for i in range((np.shape(feature_matrix)[-1])):\n",
        "        #             matrix.append(feature_matrix[:,:,i])\n",
        "        # =============================================================================\n",
        "        feature_matrix = matrix\n",
        "    for k in range(CV):\n",
        "        train_index = np.where(index_all_class != k)\n",
        "        test_index = np.where(index_all_class == k)\n",
        "        pred = np.zeros((len(test_index[0]), event_num), dtype=float)\n",
        "        # dnn=DNN()\n",
        "        for i in range(len(feature_matrix)):\n",
        "            x_train = feature_matrix[i][train_index]\n",
        "            x_test = feature_matrix[i][test_index]\n",
        "            y_train = label_matrix[train_index]\n",
        "            # one-hot encoding\n",
        "            y_train_one_hot = np.array(y_train)\n",
        "            y_train_one_hot = (np.arange(y_train_one_hot.max() + 1) == y_train[:, None]).astype(dtype='float32')\n",
        "            y_test = label_matrix[test_index]\n",
        "            # one-hot encoding\n",
        "            y_test_one_hot = np.array(y_test)\n",
        "            y_test_one_hot = (np.arange(y_test_one_hot.max() + 1) == y_test[:, None]).astype(dtype='float32')\n",
        "            if clf_type == 'DDIMDL':\n",
        "                dnn = DNN()\n",
        "                early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='auto')\n",
        "                # dnn.fit(x_train, y_train_one_hot, batch_size=128, epochs=100, validation_data=(x_test, y_test_one_hot),\n",
        "                dnn.fit(x_train, y_train_one_hot, batch_size=128, epochs=number_epochs, validation_data=(x_test, y_test_one_hot),\n",
        "                        callbacks=[early_stopping])\n",
        "                pred += dnn.predict(x_test)\n",
        "                continue\n",
        "            elif clf_type == 'RF':\n",
        "                clf = RandomForestClassifier(n_estimators=100)\n",
        "            elif clf_type == 'GBDT':\n",
        "                clf = GradientBoostingClassifier()\n",
        "            elif clf_type == 'SVM':\n",
        "                clf = SVC(probability=True)\n",
        "            elif clf_type == 'FM':\n",
        "                clf = GradientBoostingClassifier()\n",
        "            elif clf_type == 'KNN':\n",
        "                clf = KNeighborsClassifier(n_neighbors=4)\n",
        "            else:\n",
        "                clf = LogisticRegression()\n",
        "            clf.fit(x_train, y_train)\n",
        "            pred += clf.predict_proba(x_test)\n",
        "        pred_score = pred / len(feature_matrix)\n",
        "        pred_type = np.argmax(pred_score, axis=1)\n",
        "        y_true = np.hstack((y_true, y_test))\n",
        "        y_pred = np.hstack((y_pred, pred_type))\n",
        "        y_score = np.row_stack((y_score, pred_score))\n",
        "    result_all, result_eve = evaluate(y_pred, y_score, y_true, event_num, set_name)\n",
        "    # =============================================================================\n",
        "    #         a,b=evaluate(pred_type,pred_score,y_test,event_num)\n",
        "    #         for i in range(all_eval_type):\n",
        "    #             result_all[i]+=a[i]\n",
        "    #         for i in range(each_eval_type):\n",
        "    #             result_eve[:,i]+=b[:,i]\n",
        "    #     result_all=result_all/5\n",
        "    #     result_eve=result_eve/5\n",
        "    # =============================================================================\n",
        "    return result_all, result_eve"
      ],
      "metadata": {
        "id": "6qi9zZ_Pqw1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Using all the data processing, feature vector, model training functions defined, we can train the model\n",
        "Droprate, vector_size, seed and number of CV folds can be customized\n",
        "Classifiers to be used for comparison can be specified with clf_list\n",
        "\n",
        "'''\n",
        "event_num = 65\n",
        "droprate = 0.3\n",
        "vector_size = 572\n",
        "seed = 0\n",
        "CV = 5\n",
        "interaction_num = 10\n",
        "# feature_list = args['featureList']\n",
        "feature_list = [\"smile\",\"target\",\"enzyme\"] #this is default feature list\n",
        "featureName=\"+\".join(feature_list)\n",
        "# clf_list = args['classifier']\n",
        "clf_list = [\"DDIMDL\"] #choices=[\"DDIMDL\",\"RF\",\"KNN\",\"LR\"]\n",
        "for feature in feature_list:\n",
        "    set_name = feature + '+'\n",
        "set_name = set_name[:-1]\n",
        "result_all = {}\n",
        "result_eve = {}\n",
        "all_matrix = []\n",
        "drugList=[]\n",
        "for line in open(\"/content/DL4H_Team_51/DrugList.txt\",'r'):\n",
        "    drugList.append(line.split()[0])\n",
        "\n",
        "extraction = pd.read_sql('select * from extraction;', conn)\n",
        "mechanism = extraction['mechanism']\n",
        "action = extraction['action']\n",
        "drugA = extraction['drugA']\n",
        "drugB = extraction['drugB']\n",
        "\n",
        "for feature in feature_list:\n",
        "    print(feature)\n",
        "    new_feature, new_label, event_num = prepare(df_drug, [feature], vector_size, mechanism,action,drugA,drugB)\n",
        "    all_matrix.append(new_feature)\n",
        "\n",
        "\n",
        "for clf in clf_list:\n",
        "    print(clf)\n",
        "    all_result, each_result = cross_validation(all_matrix, new_label, clf, event_num, seed, CV,\n",
        "                                                set_name)\n",
        "    result_all[clf] = all_result\n",
        "    result_eve[clf] = each_result"
      ],
      "metadata": {
        "id": "-JXAB8U4I3F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "Load trained model to generate tables and figures with metrics\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (Metrics to be used for comparison)\n",
        "\n"
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plan for next phase\n",
        "  *    Run the full model to replicate the metrics presented in the original paper.\n",
        "  *    Save model checkpoint to be loaded in from Google Drive\n",
        "  *    Perform ablations by removing layers from the DDIMDL model\n",
        "  *    Compare metrics with other classifiers by using the built-in examples\n",
        "  *    Modify the number of epochs to be used for training to have the entire notebook run under 8 minutes"
      ],
      "metadata": {
        "id": "TS55FYxN1sIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Function to generate tables with metrics for model comparison with other standard models\n",
        "Print individual event metrics for each classifier\n",
        "'''\n",
        "\n",
        "# plot figures to better show the results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_overall_evaluation_results(result_all):\n",
        "    # Overall Evaluation Metrics\n",
        "    overall_metrics_labels = [\n",
        "        \"Accuracy\",\n",
        "        \"ROC AUPR (micro)\",\n",
        "        \"ROC AUPR (macro)\",\n",
        "        \"ROC AUC (micro)\",\n",
        "        \"ROC AUC (macro)\",\n",
        "        \"F1 Score (micro)\",\n",
        "        \"F1 Score (macro)\",\n",
        "        \"Precision (micro)\",\n",
        "        \"Precision (macro)\",\n",
        "        \"Recall (micro)\",\n",
        "        \"Recall (macro)\"\n",
        "    ]\n",
        "    overall_metrics_values = [result_all[i][0] for i in range(len(result_all))]\n",
        "\n",
        "    # Create a color palette for metrics\n",
        "    colors = ['skyblue'] * len(overall_metrics_labels)\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(overall_metrics_labels, overall_metrics_values, color=colors)\n",
        "    plt.xlabel('Score')\n",
        "    plt.title('Overall Evaluation Metrics')\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot\n",
        "plot_overall_evaluation_results(all_result)\n",
        "\n",
        "\n",
        "# it is better to save the numbers and figures for your presentation.\n",
        "def print_evaluation_results(result_all, result_eve):\n",
        "    print(\"Overall Evaluation Metrics:\")\n",
        "    print(f\"Overall Accuracy: {result_all[0][0]}\")\n",
        "    print(f\"Overall ROC AUPR (micro): {result_all[1][0]}\")\n",
        "    print(f\"Overall ROC AUPR (macro): {result_all[2][0]}\")\n",
        "    print(f\"Overall ROC AUC (micro): {result_all[3][0]}\")\n",
        "    print(f\"Overall ROC AUC (macro): {result_all[4][0]}\")\n",
        "    print(f\"Overall F1 Score (micro): {result_all[5][0]}\")\n",
        "    print(f\"Overall F1 Score (macro): {result_all[6][0]}\")\n",
        "    print(f\"Overall Precision (micro): {result_all[7][0]}\")\n",
        "    print(f\"Overall Precision (macro): {result_all[8][0]}\")\n",
        "    print(f\"Overall Recall (micro): {result_all[9][0]}\")\n",
        "    print(f\"Overall Recall (macro): {result_all[10][0]}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Event-specific Evaluation Metrics:\")\n",
        "    num_events = result_eve.shape[0]\n",
        "    for i in range(num_events):\n",
        "        print(f\"Event {i+1} Metrics:\")\n",
        "        print(f\"  Accuracy: {result_eve[i, 0]}\")\n",
        "        print(f\"  ROC AUPR: {result_eve[i, 0]}\")\n",
        "        print(f\"  ROC AUC: {result_eve[i, 0]}\")\n",
        "        print(f\"  F1 Score: {result_eve[i, 0]}\")\n",
        "        print(f\"  Precision: {result_eve[i, 0]}\")\n",
        "        print(f\"  Recall: {result_eve[i, 0]}\")\n",
        "#print_evaluation_results(all_result, each_result)\n",
        "from tabulate import tabulate\n",
        "def print_evaluation_results_table(result_all, result_eve, mechanism, action, drugA, drugB):\n",
        "    table_data = []\n",
        "    num_events = result_eve.shape[0]\n",
        "    for i in range(num_events):\n",
        "        metrics_data = [\n",
        "            f\"Event {i+1}\",\n",
        "            mechanism[i],\n",
        "            action[i],\n",
        "            drugA[i],\n",
        "            drugB[i],\n",
        "            result_eve[i, 0],\n",
        "            result_eve[i, 0],\n",
        "            result_eve[i, 0],\n",
        "            result_eve[i, 0],\n",
        "            result_eve[i, 0],\n",
        "            result_eve[i, 0]\n",
        "        ]\n",
        "        table_data.append(metrics_data)\n",
        "\n",
        "    headers = [\"Event\", \"Mechanism\", \"Action\", \"Drug A\", \"Drug B\", \"Accuracy\", \"ROC AUPR\", \"ROC AUC\", \"F1 Score\", \"Precision\", \"Recall\"]\n",
        "    print(tabulate(table_data, headers=headers, tablefmt=\"grid\"))\n",
        "\n",
        "# Call the function with drug pairs, mechanism, action, drugA, and drugB\n",
        "print_evaluation_results_table(all_result, each_result, mechanism, action, drugA, drugB)"
      ],
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model comparison"
      ],
      "metadata": {
        "id": "8EAWAy_LwHlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ],
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "*   The paper is fully reproducible in Google Colab Notebook environment\n",
        "*   What was easy\n",
        "  *    Working with clearly defined sections/functions for fitting into Colab Notebook\n",
        "  *    Not too complex code for feature engineering, training, cross-validation\n",
        "  *    Easy to test other types of models for comparison using built in functions\n",
        "*    What was difficult\n",
        "  *    Figuring out what packages/functions are deprecated with Colab packages\n",
        "  *    Modernizing inputs and outputs of functions that require different syntax\n",
        "  *    Rewriting functions to have them work with one notebook instead of working with several different script files\n",
        "*   Suggestions to the author\n",
        "  *    Use modern packages and rewrite couple functions to make them work with modern packages\n",
        "  *    Clearer instructions for initializing the model with user inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8SI64iYv_Bh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1.   @article{deng2020multimodal,\n",
        "title={A multimodal deep learning framework for predicting drug-drug interaction events},\n",
        "author={Deng, Yifan and Xu, Xinran and Qiu, Yang and Xia, Jingbo and Zhang, Wen and Liu, Shichao},\n",
        "journal={Bioinformatics}\n",
        "}\n",
        "\n",
        "2. https://github.com/YifanDengWHU/DDIMDL\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}